name: GenAI Research Assistant CD to Hugging Face

on:
  workflow_run:
    workflows: ["GenAI Research Assistant CI"]
    branches: [main, master]
    types:
      - completed
  # Optional: Enable manual deployment
  workflow_dispatch:

jobs:
  deploy-to-huggingface:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Login to Hugging Face
        run: |
          pip install huggingface_hub
          # Create HF credentials file directly
          mkdir -p ~/.huggingface
          echo "{ \"api_key\": \"${{ secrets.HF_TOKEN }}\" }" > ~/.huggingface/token
      
      - name: Create Dockerfile for Hugging Face
        run: |
          cat > Dockerfile << EOL
          FROM python:3.11-slim

          WORKDIR /app

          # Install Node.js, npm, and other system dependencies
          RUN apt-get update && apt-get install -y \\
              nodejs \\
              npm \\
              supervisor \\
              curl \\
              build-essential \\
              git \\
              && rm -rf /var/lib/apt/lists/*

          # Copy requirements first for better caching
          COPY requirements.txt .
          RUN pip install --no-cache-dir -r requirements.txt

          # Copy backend application
          COPY app/ ./app/
          
          # Set up frontend
          WORKDIR /app/frontend
          COPY frontend/package*.json ./
          RUN npm install
          COPY frontend/ ./
          
          # Set Node.js OpenSSL legacy provider for compatibility
          ENV NODE_OPTIONS=--openssl-legacy-provider
          
          # Build frontend
          RUN npm run build
          
          # Return to app directory
          WORKDIR /app
          
          # Install serve for frontend
          RUN npm install -g serve
          
          # Create directory for persistent storage
          RUN mkdir -p /app/tmp
          
          # Create a non-root user to run the app
          RUN useradd -m appuser && \\
              mkdir -p /tmp/supervisor && \\
              chown -R appuser:appuser /app /tmp/supervisor

          # Copy supervisor configuration
          COPY docker/supervisord.conf /tmp/supervisor/supervisord.conf
          
          # Modify the supervisord config for Hugging Face port
          RUN sed -i 's/--port 8000/--port 7860/g' /tmp/supervisor/supervisord.conf

          # Copy app.py to root
          COPY app.py .

          # Set environment variables
          ENV PYTHONPATH=/app
          ENV NODE_ENV=production
          ENV PORT=7860

          # Switch to non-root user
          USER appuser

          # Expose the port Hugging Face will use
          EXPOSE 7860

          # Run the app with supervisord
          CMD ["/usr/bin/supervisord", "-c", "/tmp/supervisor/supervisord.conf"]
          EOL
      
      - name: Create Hugging Face Space README
        run: |
          cat > README.md << EOL
          ---
          title: GenAI Research Assistant
          emoji: ðŸ”Ž
          colorFrom: indigo
          colorTo: purple
          sdk: docker
          app_port: 7860
          pinned: true
          license: mit
          ---

          # GenAI Research Assistant

          A powerful AI-powered research assistant that helps you search, analyze, and synthesize information from various sources.

          ## Features

          - Multi-model LLM support (OpenAI, Google, Meta)
          - Document-based question answering
          - Chat memory and conversation history
          - Modern React frontend with responsive design

          ## Environment Setup

          To use this application, set the following environment variables in your Hugging Face Space settings:

          - \`OPENAI_API_KEY\`: Your OpenAI API key
          - \`GOOGLE_API_KEY\`: Your Google AI Studio API key
          - \`META_API_KEY\`: Your Meta API key
          - \`DATABASE_URL\`: (Optional) Database connection string

          ## Learn More

          [Visit GitHub Repository](https://github.com/yourusername/genai-research-assistant)

          ---
          *Deployed via GitHub Actions to Hugging Face Spaces*
          EOL
      
      - name: Create app.py for Hugging Face
        run: |
          # Create a simple app.py that imports the main app
          cat > app.py << EOL
          from app.main import app

          # This file is required by Hugging Face Spaces
          # The actual application is defined in app/main.py
          EOL
      
      - name: Push to Hugging Face Space
        env:
          HF_SPACE_NAME: ${{ secrets.HF_SPACE_NAME }}
          HF_USERNAME: ${{ secrets.HF_USERNAME }}
        run: |
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          # Clone the Hugging Face Space repo (or create it if it doesn't exist)
          if ! git clone https://huggingface.co/spaces/$HF_USERNAME/$HF_SPACE_NAME repo; then
            mkdir -p repo
            cd repo
            git init
            git remote add origin https://huggingface.co/spaces/$HF_USERNAME/$HF_SPACE_NAME
            cd ..
          fi
          
          # Copy necessary files
          cp -r app/ repo/
          cp -r frontend/ repo/
          cp requirements.txt repo/
          cp Dockerfile repo/
          cp README.md repo/
          cp -r docker/ repo/
          cp app.py repo/
          
          # Create .gitattributes for LFS
          echo "*.bin filter=lfs diff=lfs merge=lfs -text" > repo/.gitattributes
          
          # Create Docker configuration for Hugging Face
          mkdir -p repo/.config/huggingface
          cat > repo/.config/huggingface/settings.json << EOL
          {
            "docker_enabled": true
          }
          EOL
          
          # Commit and push changes
          cd repo
          git add .
          git commit -m "Update Space with latest GenAI Research Assistant"
          git push -f https://${{ secrets.HF_USERNAME }}:${{ secrets.HF_TOKEN }}@huggingface.co/spaces/$HF_USERNAME/$HF_SPACE_NAME main
      
      - name: Wait for deployment and post status
        env:
          HF_SPACE_NAME: ${{ secrets.HF_SPACE_NAME }}
          HF_USERNAME: ${{ secrets.HF_USERNAME }}
        run: |
          echo "Deploying to Hugging Face Space: https://huggingface.co/spaces/$HF_USERNAME/$HF_SPACE_NAME"
          echo "Deployment triggered! It may take a few minutes to complete."
          echo "IMPORTANT: Remember to set the following environment variables in your Hugging Face Space settings:"
          echo "- DATABASE_URL (if using external database)"
          echo "- OPENAI_API_KEY"
          echo "- GOOGLE_API_KEY"
          echo "- META_API_KEY" 